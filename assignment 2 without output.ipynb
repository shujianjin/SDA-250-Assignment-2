{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c08c1d-96ad-4137-b3a9-730cd6c658f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "df = pd.read_csv('IMDB Dataset.csv',  encoding='windows-1252')\n",
    "dl = pd.read_csv('sentiment labels.csv', encoding='windows-1252')\n",
    "\n",
    "# Preprocess the data\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')\n",
    "stemmer = PorterStemmer()\n",
    "#generalizing the text\n",
    "def preprocess_text(text):\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text).lower()\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "    text = ' '.join(words)\n",
    "    return text\n",
    "\n",
    "#get the list of reviews which are all the same format\n",
    "df['review'] = df['review'].apply(preprocess_text)\n",
    "\n",
    "print(df['review'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cb3eb8-771d-4ae7-809b-1dc6aeb24e46",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "#importing the real labels which dataset originally has.\n",
    "with open('Labelssss.csv', mode='r') as file:\n",
    "\n",
    "    # Create a reader object\n",
    "    reader = csv.reader(file)\n",
    "\n",
    "    # Convert the reader object to a list\n",
    "    label = list(reader)\n",
    "\n",
    "filtered_list = [word for word in label if not word in stop_words]\n",
    "filtered_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b538bb7c-97e4-424e-bcdd-84346d1f39fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aeafa3c-a1db-4fe8-ac76-939ed6ae6de7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Sentiment Analysis by using vader by myself\n",
    "#The vader has default trained data, therefore skip spliting the data into trained/test data.\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "sentences = df['review']\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "for sentence in sentences:\n",
    "    vs = analyzer.polarity_scores(sentence)\n",
    "    print(\"{:-<65} {}\".format(sentence, str(vs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa89275-8630-4dd8-867e-a56cb4f08f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print dataframe \n",
    "df['scores'] = df['review'].apply(lambda review: analyzer.polarity_scores(review))\n",
    "df['compound']  = df['scores'].apply(lambda score_dict: score_dict['compound'])\n",
    "df['comp_score'] = df['compound'].apply(lambda c: 'positive' if c >=0 else 'negative')\n",
    "comp_score=df['comp_score']\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0620df61-edc2-424b-aedc-0b9b21f78d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "#review are the same for both trained and test data\n",
    "#the IMDB dataset has correct labels on the file, therefore use it for calculating accuracy. \n",
    "texts = df['review']\n",
    "true_labels = filtered_list\n",
    "\n",
    "predicted_labels = []\n",
    "for text in texts:\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "    if scores['compound'] > 0:\n",
    "        predicted_labels.append(\"positive\")\n",
    "    elif scores['compound'] < 0:\n",
    "        predicted_labels.append(\"negative\")\n",
    "\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7f5195-5981-4e7b-918a-23f6b2a6442b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6994124-2be0-40dc-a8a9-6ae63dfcea8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1 (v3.11.1:a7a450f84a, Dec  6 2022, 15:24:06) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
